# Prompt_engineering
Aprenda a fazer um prompt para seus agentes 

# 5 partes: 

<img width="200" height="300" alt="Captura de tela 2025-09-01 225001" src="https://github.com/user-attachments/assets/265c65d8-0488-4815-ac8a-0e85b35f0179" />

## üßª Papel

<img width="200" height="30" alt="image" src="https://github.com/user-attachments/assets/64a34f96-971b-4c12-8115-decd82eb6cbf" />

A atribui√ß√£o de papel √© uma t√©cnica onde ao modelo de linguagem √© atribu√≠do um papel espec√≠fico para desempenhar durante a intera√ß√£o. Isso ajuda a imergir o modelo no papel e pode melhorar o desempenho em tarefas subsequentes.

Exemplo:
   - "Voc√™ √© um roteirista de conte√∫do de formato curto altamente qualificado e criativo, com um talento para criar v√≠deos envolventes, informativos e concisos."

Neste exemplo, o papel (roteirista de conte√∫do de formato curto altamente qualificado e criativo) √© estabelecido, e qualidades-chave (envolvente, informativo, conciso) s√£o destacadas para enfatizar a aptid√£o do modelo neste papel.

### Resultados da Pesquisa: üöÄ
- Quando atribu√≠do um papel vantajoso, a precis√£o aumentou em 10,3%
- Descri√ß√µes elogiosas de suas habilidades aumentaram ainda mais a precis√£o (~15-25% de aumento total!)


## üìï Tarefa
<img width="200" height="30" alt="image" src="https://github.com/user-attachments/assets/81ea8e76-e89e-4e80-b573-ebd89bcc3269" />

A tarefa √© o que a maioria das pessoas normalmente fornece a um modelo esperando um resultado. √â uma descri√ß√£o direta do que elas querem alcan√ßar.

Exemplo:
- "Gere mensagens de contato (outreach) casuais e envolventes para usu√°rios que procuram promover seus servi√ßos na ind√∫stria odontol√≥gica, focando especialmente na integra√ß√£o de ferramentas de IA para escalar neg√≥cios. Suas mensagens devem ser diretas, amig√°veis e personalizadas para o destinat√°rio, incentivando uma conversa sobre como a IA pode beneficiar o neg√≥cio dele."

Notas sobre Como Escrever Tarefas:
- Sempre comece com um verbo (ex: gere, escreva, analise)
- Seja descritivo e preciso, mantendo o texto breve.
- Dependendo do caso de uso, √© aqui que voc√™ pode inserir suas vari√°veis (veja abaixo)

Exemplo com Vari√°veis:

"Gere mensagens de contato casuais e envolventes para usu√°rios que procuram promover seus servi√ßos ou produtos espec√≠ficos de um nicho, focando especialmente na integra√ß√£o de ferramentas de IA para escalar neg√≥cios. Suas mensagens devem ser diretas, amig√°veis e personalizadas para o destinat√°rio, incentivando uma conversa sobre como a IA pode beneficiar o neg√≥cio dele. Abaixo est√£o os detalhes para os quais voc√™ deve gerar o conte√∫do.
- Nicho: {{nicho}}
- Oferta: {{oferta}}"


## üìí Espec√≠ficos 
<img width="200" height="30" alt="image" src="https://github.com/user-attachments/assets/656ebe86-643f-4d53-84de-21b06e4a4c00" />

A se√ß√£o de especifica√ß√µes √© uma oportunidade para listar as notas mais importantes sobre a execu√ß√£o da tarefa descrita acima.

O formato de lista permite que voc√™ adicione facilmente novas instru√ß√µes enquanto testa e melhora o prompt. Claro, tente n√£o acumular informa√ß√µes desnecess√°rias aqui. Menos √© mais.

Exemplo de Especifica√ß√µes:
- Cada mensagem deve ter uma introdu√ß√£o, corpo e conclus√£o, com um tom informal e envolvente.
- Use placeholders como (user.firstname) para personalizar as introdu√ß√µes.
- Etc.

## üìù Contexto
<img width="200" height="40" alt="image" src="https://github.com/user-attachments/assets/5ff2f55f-914a-427e-81a3-c4caa1be9a24" />

Fornecer contexto sobre em qual ambiente o LLM est√° operando e por que ele est√° realizando essa tarefa espec√≠fica pode ajudar a aumentar ainda mais o desempenho.

Isso combina t√©cnicas anteriores como a Atribui√ß√£o de Papel (Role Prompting), ao esclarecer ainda mais quem ele √©, o que est√° fazendo e por que est√° fazendo. O Prompt Emocional (EmotionPrompt) tamb√©m pode ser usado aqui ao explicar a import√¢ncia do papel do LLM no sucesso do neg√≥cio e at√© mesmo da sociedade como um todo.

Exemplo Espec√≠fico:
- "Nossa empresa fornece solu√ß√µes baseadas em IA para neg√≥cios de diversas ind√∫strias. Recebemos um alto volume de e-mails de potenciais clientes atrav√©s do formul√°rio de contato do nosso site. Seu papel na classifica√ß√£o desses e-mails √© essencial para que nossa equipe de vendas priorize seus esfor√ßos e responda √†s solicita√ß√µes em tempo h√°bil. Ao identificar com precis√£o as oportunidades e os e-mails que precisam de aten√ß√£o, voc√™ contribui diretamente para o crescimento e sucesso de nossa empresa, portanto, valorizamos muito sua cuidadosa considera√ß√£o e aten√ß√£o √† classifica√ß√£o."

Notas Gerais:
- Forne√ßa contexto sobre o neg√≥cio, incluindo clientes, tipos de servi√ßos ou produtos, valores da empresa, etc.
- Forne√ßa contexto sobre o sistema do qual faz parte. Ex: quando clientes enviam nosso formul√°rio no site, n√≥s recebemos um e-mail, voc√™ ent√£o...
- Forne√ßa contexto sobre a import√¢ncia da tarefa e o impacto no neg√≥cio e/ou na sociedade como um todo.


## üìó Exemplos
<img width="200" height="100" alt="image" src="https://github.com/user-attachments/assets/30a14bf7-667d-403f-b2bb-5e5f36099e91" />

Na se√ß√£o de exemplos, usamos uma t√©cnica conhecida como Few-Shot Prompting (Prompting com Poucos Exemplos) para aumentar o desempenho e ajustar finamente o tom, o formato e o comprimento da resposta.

Isso ocorre quando v√°rios exemplos de entrada e sa√≠da s√£o fornecidos ao modelo de linguagem como parte do prompt. Isso permite que o modelo execute novas tarefas sem a necessidade de ajuste fino (fine-tuning).

Resultados da Pesquisa: üöÄ
- O GPT-3 175B alcan√ßou uma melhora m√©dia de 14,4% sobre sua precis√£o de zero-shot (nenhum exemplo) de 57,4% ao usar 32 exemplos por tarefa.

Principais Conclus√µes:
- Fornecer apenas alguns exemplos melhora significativamente o desempenho em compara√ß√£o com o prompting zero-shot (sem exemplos).
- A precis√£o escala com o n√∫mero de exemplos, mas apresenta retornos decrescentes.
- A maior parte dos ganhos pode ser alcan√ßada com 10 a 32 exemplos bem-elaborados.

## üìÉ Notas
<img width="200" height="30" alt="image" src="https://github.com/user-attachments/assets/55506af1-354d-4540-b338-a8bf7da8f25b" />

A se√ß√£o de notas √© sua √∫ltima chance de lembrar o LLM (Modelo de Linguagem Grande) dos aspectos-chave da tarefa e adicionar quaisquer detalhes finais para ajustar as sa√≠das ao seu estilo desejado.

Suas notas formam uma lista que consiste em coisas como:
- Notas de formata√ß√£o da sa√≠da, ex: ‚Äúsua sa√≠da deve estar no formato x‚Äù
- Prompting negativo: ‚ÄúN√ÉO fa√ßa x‚Äù
- Ajustes de tom
- Lembretes de pontos-chave da tarefa ou das especifica√ß√µes

Esta lista de notas geralmente come√ßa enxuta e acaba com algumas linhas de profundidade ap√≥s algumas rodadas de testes e ajustes. √â nesta lista que voc√™ pode adicionar coisas sem precisar refatorar o prompt inteiro.

A inclus√£o da se√ß√£o de 'notas' nesta f√≥rmula de prompt √© baseada no efeito ‚ÄúPerdido no Meio‚Äù (Lost in the Middle), que destaca uma limita√ß√£o significativa na forma como os modelos de linguagem lidam com grandes quantidades de tokens de entrada.
